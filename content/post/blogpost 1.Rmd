---
title: "Working with Survey Monkeys"
author: "Rika Gorn"
date: "February 3, 2019"
output: md_document
---

#Working with Survey...Monkeys?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(socviz)
library(glue)
library(knitr)
library(scales)
library(kableExtra)
library(dplyr)
library(tidyr)
library(readxl)
library(janitor)
library(ggplot2)
library(ggthemes)
library(forcats)
library(corrplot)
library(stringr)
library(tidyverse)
library(here)
```

As a data practicioner in the public sector, I frequently work on data compiled through surveys. We use surveys to get a feel for how clients are reacting to various programming, to analyze qualitative and quantitative data, and even to compile demographics. 90% of the time, the data is collected through [SurveyMonkey](http://surveymonkey.com) - an online tool that works pretty well, especially if you upgrade to a paid version. As with any online software tool that optimizes UI through point and click tools, it has a few quirks. 

If, like me, you want to do the analysis on your own or in some other tool like R, I've found that there are a handful of best practices that can help.  I wanted to write a blogpost that went through some ways to work through these quirks, summarize likert style data, and create some easy, quick, and pretty visualizations.

### Exporting SM data

In the **Analyze Results** tab, SM allows users to download their data in a variety of ways. You can download the following in csv, xlsx, pdf, or spss outputs: 

![surveymonkey screenshot](images/"export.png")

* All summary data - I have not found this useful for my own analysis. This simply spits out the aggregate results of each question. 

* All responses data - exports the raw dataset with individual responses as rows and questions as columns. This is what I primarily use for my analysis.

* All individual responses - exports all the answers for a specific individual.

### Cleaning data

In a standard survey, I will usually have a mix of demographic, binary, and likert scale questions. When I load my data in R as a .csv, however, I can quickly see that survey monkey has a funny way of organizing the different questions and their associated labels. It looks like the headers for the data are included over the first two rows of our data table, depending on the type of question. 


```{r echo = FALSE, message = FALSE, warning = FALSE}
mysurvey <- read_csv(here("mysurvey.csv"))
```

Binary questions have correct headers but then the first row for each column has the character "Response". 
```{r echo = FALSE}
mysurvey[1:4, 7:10]
```

Questions where the user can give multiple answer choices are spread across several columns identified by unnamed headers X4, X5, X6, etc.
```{r echo = FALSE}
(mysurvey)[1:4,3:6]
```

Likert questions have a blank header and our likert statement is included in the 1st row of each column. 
```{r echo = FALSE}
mysurvey[1:4,14]
```

Finally, all of our factors are characters. Basically, its a mess!

Ok, so what now. My first step always, is to do a bit of basic cleaning with the wonderful [janitor] (https://github.com/sfirke/janitor) package. For the race category I want to combine the multiple choices into one column, and I only want to know the first category identified by each respondent. For this, the janitor package also has a handy function called coalesce(). 

```{r}
library(janitor)
mysurvey <- mysurvey %>% clean_names() %>% 
  mutate(race = coalesce(what_is_your_race, x4, x5, x6)) %>% 
  select(-what_is_your_race, -x4, -x5, -x6)  
```

```{r echo=FALSE}
mysurvey[1:10,14]
```
  
Next, whenever I have the meta data for a dataset separated up over multiple rows, I like to generate a data dictionary so that I don't get confused. I can also refer back to it, if and usually when something goes wrong!

```{r}
names <- c("age", "gender", "so", "smoker", "borough", "hsd", "get_info", "file_complaint", "Q1", "Q2", "Q3", "Q4", "Q5", "race")
data_dictionary <- mysurvey[1,] 
names(data_dictionary) <- names
data_dictionary <- data_dictionary %>% as.data.frame  %>% 
  rownames_to_column(., 'Var1') %>% select(-Var1) %>% 
  gather(key = "Question", value = "label", convert = TRUE)

data_dictionary[7, 2] <- "I know where to get information on safety rights and/or reporting"
data_dictionary[8, 2] <- "I know who to talk to or how to file a complaint if I feel unsafe"
data_dictionary[14,2] <- "Response"

data_dictionary
```

So I did a slightly weird thing here. I know I'm going to be doing analysis with my likert statements, but I'd really prefer not having to type out the entire statement or having it be included in my summary tables. Instead, I renamed all the likert statements to a simple alphanumeric, and kept the actual statement in the label column. Also, if your other variables include interesting response choices or things that you'd like to note for yourself, you can specify them in the label column here. I really like having something like this, even if it includes a touch more work. 

Next we need to actually clean up the first two rows of our dataframe. Since we already have our list of column names from creating the data dictionary, all we need to do is rename the dataframe, remove the 2nd row of meta-data, and parse the columns accordingly. And now we have a dataset that we can work with!

```{r}
names(mysurvey) <- names
mysurvey <- mysurvey[-1,]   #finally getting rid of that awful first row

mysurvey$age <- parse_number(mysurvey$age)
cols <- colnames(mysurvey[ ,2:14])
mysurvey[,cols] <- lapply(mysurvey[,cols], as.factor)

glimpse(mysurvey)

```

The last thing I'd like to do to clean our data is change all the likert scale questions to ordered factors. I could have probably done this above in my parsing but two steps makes things a bit more explcit so what the hell, why not?!

```{r}
likert_scale <- c("Strongly disagree", "Disagree", "Neutral", "Agree", "Strongly agree")

mysurvey <- mysurvey %>% 
  mutate_at(vars(matches("^Q")), funs(factor(., levels = likert_scale, ordered = TRUE)))
```


### Analyzing and Summarizing

Whenever I do any sort of analysis, I like to first quickly summarize my data. This is helpful both for reporting purposes and for explaining analysis to non-stats folks. Especially, for chi-square or t-test analysis, its always nice to see a quick contingency table or cross-tab which can help intuitively explain when certain variables are associated with one another. 

The benefit and sometimes the curse of R is that there are multiple ways of doing the same thing. Let's look at a few ways of summarizing 



```{r}
mysurvey %>% select(borough, file_complaint) %>% 
group_by(borough) %>%  
  count(borough, file_complaint) %>%
  mutate(perc = round(prop.table(n)*100, digits = 0)) %>% # you can also use 'n/sum(n)' instead of prop.table here
  select(-n) %>% 
  mutate(perc = paste0(perc, "%")) %>% 
  spread(borough, perc) 
```

```{r}
prop.table(table(mysurvey$borough, mysurvey$file_complaint, useNA = "always"), margin = 1)*100 #margin tells prop.table which group we are distributing by which group
```



